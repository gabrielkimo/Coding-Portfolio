mtcarapp.R - 
  * This is a project in which I designed an app in R that would take the mtcars dataset from 
    R, and allow the user to create different types of plot from a chosen variable in the dataset, while also displaying 
    general summary statistics for the selected variable.
  * Functionality includes a bar to filter the plotted variable by it's corresponding MPG values for each 
    observation, and tooltips appear when hovering the mouse over anything the user can interact with.
  * Compatability with the selected variable and the desired plot type is verified by the app, protecting from most use-cases 
    where a plot would return as innaccurate or empty.

PSTAT100 FinalProject.rmd, PSTAT100 FinalProject.pdf, and titanic.csv -
  * The files PSTAT100 FinalProject.rmd and PSTAT100 FinalProject.pdf contain the code and generated report 
    respectively for a project where my group and I worked with our chosen data set, titanic.csv, in an effort to build 
    predictive models.  
  * Over the course of the project we performed prelimanary data analysis, cleaned the data, and developed our own 
    hypotheses. 
  * We then used logistic regression modeling and the Wilcoxon rank-sum test in R to test our hypotheses, and presented our 
    conclusions within the report based on the results of our models and hypothesis testing.  

Final-Project-PSTAT-131-1.rmd, Final-Project-PSTAT-131-1.pdf, and heart-attack-risk-prediction-dataset.csv - 
  * The files Final-Project-PSTAT-131-1.rmd and Final-Project-PSTAT-131-1.pdf contain the code and generated report for a
    machine learning project where my partner and I used our chosen dataset, heart-attack-risk-prediction-dataset.csv,
    with the goal of making predictions about a persons risk of suffering aheart attack.
  * We began by performing exploratory data analysis to identify any observations that were incomplete, and any variables
    that would need to be coerced to a different data type (i.e. a factor with two levels rather than a string), then
    randomly splitting our data into training and test sets for cross validation of predictions.
  * Then we trained and evaluated the efficacy of three different models: logistic regression, boosting, and
    k-nearest-neighbors classification.
  * Finally with our model evaluations completed, we developed plans for improving the accuracy of our models predictions.
    
